# Managing Applications with Kubernetes
## ReplicaSetの復習ノート

### 講義のテーマ

この講義は、Kubernetesにおける**ReplicaSet**の役割と機能、およびその利点について解説しています。特に、単一Pod構成の課題を解決し、**高可用性**や**スケーラビリティ**を実現するための重要な概念であることを強調しています。

-----

### ReplicaSetとは何か？

  * **定義**: ReplicaSetは、指定された数のPodが常に稼働している状態を維持することを保証するKubernetesのコントローラーです。
  * **主な役割**: 実際のPod数（Actual State）を望ましいPod数（Desired State）に一致させるようにPodを管理します。
      * Podが不足している場合は、新しいPodを作成します。
      * Podが過剰な場合は、余分なPodを削除します。
      * Podが故障した場合は、新しいPodに置き換えます。
  * **利点**:
      * **高可用性**: 冗長なPodを持つことで、単一障害点をなくし、ダウンタイムを最小限に抑えます。
      * **スケーリング**: アプリケーションの需要に応じてPodの数を増減させることができます。
      * **自動復旧**: 故障したPodを自動的に置き換えることで、サービスの継続性を確保します。

-----

### ReplicaSetの動作

ReplicaSetは、Podを直接所有するのではなく、**Podラベル**を使って管理対象のPodを識別します。これにより、Kubernetesのオブジェクト間の独立性が保たれます。

  * **Podラベル**: ReplicaSetは、マニフェストファイルで指定されたラベルを持つPodを監視し、管理します。

-----

### DeploymentとReplicaSetの関係

  * **推奨される使い方**: ほとんどの場合、ReplicaSetを直接作成・操作するのではなく、**Deployment**を通じて管理することが推奨されます。
  * **役割分担**:
      * **Deployment**: ReplicaSetを管理し、Podの宣言的なアップデート（更新）などを提供します。
      * **ReplicaSet**: Deploymentによって作成され、Podの数と状態を維持する役割に専念します。

-----

### コマンド例

ReplicaSetの動作を確認するための基本的なコマンドを以下に示します。

#### 1\. Deploymentの作成と確認

```bash
# deploymentを作成
kubectl create deployment hello-kubernetes --image=k8s.gcr.io/echoserver:1.10

# deploymentが作成されたことを確認
kubectl get deploy

# deploymentによって作成されたpodを確認
kubectl get pods

# deploymentによって作成されたreplicasetを確認
kubectl get rs
```

#### 2\. ReplicaSetのスケール操作

  * DeploymentのPod数を3にスケールする場合

<!-- end list -->

```bash
kubectl scale deployment hello-kubernetes --replicas=3
```

  * スケール後のPodの確認

<!-- end list -->

```bash
kubectl get pods
```

#### 3\. 状態の維持（Podの削除と自動復旧）

  * Podを意図的に削除しても、ReplicaSetが新しいPodを作成して元のPod数に戻すことを確認する。

<!-- end list -->

```bash
# Podを削除
kubectl delete pod <pod-name>

# 新しいPodが作成されたことを確認
kubectl get pods
```

-----

## Kubernetesにおけるオートスケーリング

オートスケーリングは、需要に応じてクラスタを自動的にスケールさせることで、リソース利用を最適化し、コストを削減する機能です。Kubernetesでは、ノードレベルとPodレベルの2つのレイヤーでオートスケーリングが可能です。

-----

### オートスケーリングの種類

Kubernetesには以下の3種類のオートスケーラーがあります。

#### 1\. Horizontal Pod Autoscaler (HPA)

**Podの数を増減させて水平にスケーリング**します。CPUやメモリの使用率などのメトリクスに基づいて、アプリケーションのレプリカ（Pod）数を自動的に調整します。

  * **機能**:
      * 需要に応じて、実行中のPodの数を**自動的に増減**させます。
      * Deploymentなどのワークロードリソースに対して動作します。
  * **例**: 朝の負荷が低い時間帯はPodが1つで十分だが、ピーク時にはPodを3つに増やす。負荷が下がるとPodを削除して元の数に戻す。
  * **コマンド例**:
    ```bash
    kubectl autoscale deployment <deployment-name> --min=2 --max=10 --cpu-percent=50
    ```
    これは、CPU使用率が50%に達すると、Podの数を最小2、最大10の範囲で自動調整する設定です。

#### 2\. Vertical Pod Autoscaler (VPA)

**Podのリソースを増減させて垂直にスケーリング**します。Podが使用するCPUやメモリの量（リソースリクエストとリミット）を調整します。

  * **機能**:
      * アプリケーションの需要に応じて、**個々のPodに割り当てるリソース（CPU、メモリ）を自動的に増減**させます。
      * 水平スケーリングが不可能な、または理想的でないサービスに適しています。
  * **例**: 朝の負荷が低い時間帯はPodのリソースを少なく保ち、ピーク時にはPodのリソース（CPU、メモリ）を増やしてパフォーマンスを向上させる。
  * **注意点**: HPAとVPAをCPUやメモリのような同じリソースメトリクスで同時に使用することは推奨されません。

#### 3\. Cluster Autoscaler (CA)

**ノードの数を増減させてクラスタ自体をスケーリング**します。これにより、Podが実行されるノードの数を自動的に調整します。

  * **機能**:
      * スケジュールできないPodがある場合や、ノードの容量に対して需要が増減する場合に、クラスタのノードを**自動的に追加または削除**します。
      * HPAやVPAでPodがスケールされた結果、ノードが過負荷になった場合にノードを追加します。
  * **例**: 負荷が低いときはノードの数を少なく保ち、需要が増えてPodが増えると、新しいノードを追加してPodを再分散させる。負荷が下がると、不要になったノードを削除してコストを削減する。

-----

### まとめ

| スケーラーの種類 | スケーリングの対象 | スケーリングの方法 |
| :--- | :--- | :--- |
| **HPA** | Pod | Podの**数**を増減させる（水平スケーリング） |
| **VPA** | Pod | Podの**リソース**を増減させる（垂直スケーリング） |
| **CA** | クラスタ | クラスタの**ノード数**を増減させる |

これら3つのオートスケーラーを組み合わせて使用することで、ピーク時の安定したサービス運用と、低需要時のコスト削減を両立させる、最も最適化されたソリューションを構築できます。

はい、承知いたしました。
講義のトランスクリプトを基に、復習用の要点ノートをMarkdown形式で作成します。

---

## Kubernetesのデプロイ戦略

この講義では、Kubernetes環境でアプリケーションを安全かつ効率的に更新するための様々な**デプロイ戦略**を学びます。各戦略の仕組み、メリット・デメリットを理解し、状況に応じて最適な手法を選択できるようになることが目的です。

### デプロイ戦略の基本

* **デプロイ戦略とは**: アプリケーションの更新やライフサイクルを自動で管理し、**リスクを最小限に抑える**ための手法。
* **主な目的**:
    * アプリケーションのデプロイ、更新、ロールバック（問題発生時に前のバージョンに戻すこと）
    * デプロイの一時停止と再開
    * 手動または自動でのスケーリング（Pod数の調整）

---

### 6つの主要なデプロイ戦略

#### 1. リクリエイト戦略 (Recreate)
古いバージョンを**すべて停止**してから、新しいバージョンを**一度に起動**する最もシンプルな戦略です。

* **流れ**:
    1.  稼働中の全Pod (v1) を削除する。
    2.  新しい全Pod (v2) を作成する。
* **メリット**:
    * 仕組みが非常に**シンプル**。
    * アプリケーションの状態が完全に新バージョンに切り替わる。
* **デメリット**:
    * 新旧の入れ替え時に**短いダウンタイムが発生**する。

| Pros | Cons |
| :--- | :--- |
| ✅ シンプルな設定 | ❌ 短いダウンタイムが発生 |
| ✅ アプリケーションを完全に置換 | |

#### 2. ローリングアップデート戦略 (Rolling / Ramped)
古いバージョンのPodを**一つずつ順番に**新しいバージョンのPodへ置き換えていく戦略です。KubernetesのDeploymentにおけるデフォルト戦略です。

* **流れ**:
    1.  v1のPodを1つ削除する。
    2.  v2のPodを1つ作成し、置き換える。
    3.  全てのPodがv2になるまで上記を繰り返す。
* **メリット**:
    * 常にどちらかのバージョンが稼働しているため、**ダウンタイムがほぼない**。
    * ステートフルなアプリケーション（データを保持するアプリ）にも適している。
* **デメリット**:
    * 全体の入れ替えに**時間がかかる**。
    * 新旧バージョンへのトラフィック分散を細かく制御できない。

| Pros | Cons |
| :--- | :--- |
| ✅ シンプルな設定 | ❌ ロールアウト/ロールバックに時間がかかる |
| ✅ ステートフルアプリに適応可能 | ❌ トラフィック分散の制御が不可 |

#### 3. ブルー/グリーン戦略 (Blue/Green)
現在稼働中の環境（**Blue**）とは別に、全く同じ構成で新バージョンの環境（**Green**）を用意し、テスト完了後にトラフィックを**一斉にGreenへ切り替える**戦略です。

* **流れ**:
    1.  本番環境(Blue)と全く同じ構成で新バージョン環境(Green)を構築する。
    2.  Green環境で十分にテストを行う。
    3.  テスト完了後、ロードバランサー等でトラフィックをBlueからGreenへ一気に切り替える。
* **メリット**:
    * トラフィックの切り替えが瞬時に行えるため、**ダウンタイムがない**。
    * 問題発生時も、トラフィックをBlueに戻すだけで**即座にロールバック**できる。
* **デメリット**:
    * 常に2つの環境を維持するため、**リソース（コスト）が2倍**必要。
    * 本番リリース前の厳密なテストが不可欠。

| Pros | Cons |
| :--- | :--- |
| ✅ 瞬時のロールアウト/ロールバック (ダウンタイムなし) | ❌ **高コスト (リソースが2倍)** |
| ✅ 全ユーザーへ即座に新バージョンを提供 | ❌ 事前の厳密なテストが必須 |
| | ❌ ステートフルアプリの扱が難しい |

#### 4. カナリー戦略 (Canary)
新しいバージョンを**一部のユーザーにのみ先行公開**し、問題がないことを確認しながら段階的に全ユーザーへ展開していく戦略です。炭鉱のカナリアが語源です。

* **流れ**:
    1.  新バージョン(v2)をデプロイする。
    2.  ごく一部のユーザーからのトラフィックだけをv2に流す。
    3.  エラー率やパフォーマンスを監視し、問題がなければ徐々にv2へのトラフィック比率を上げていく。
    4.  最終的に全てのトラフィックをv2に向ける。
* **メリット**:
    * **本番環境でリスクを最小限に抑えながら**新バージョンをテストできる。
    * 問題発生時の影響範囲が限定的で、**素早いロールバックが可能**。
* **デメリット**:
    * 全体の展開が完了するまでに**時間がかかる**。

| Pros | Cons |
| :--- | :--- |
| ✅ 信頼性・エラー・性能監視に便利 | ❌ ロールアウトが遅い |
| ✅ 高速なロールバック | |

#### 5. A/Bテスト戦略 (A/B Testing)
主にUIの改善など、**複数のバージョンを比較評価**するために使われる戦略です。特定の条件（地域、言語、ブラウザなど）に基づいてユーザーをセグメント分けし、異なるバージョンを割り当てます。

* **流れ**:
    1.  比較したい複数バージョン（A, B）を用意する。
    2.  特定の条件に合うユーザー群を定義する。
    3.  定義したユーザー群からのリクエストを、対応するバージョンに振り分ける。
    4.  ユーザーの反応や各種指標を分析し、最も良いバージョンを決定して全体に展開する。
* **メリット**:
    * **データに基づいて**最適なバージョンを決定できる。
    * トラフィックの分配を細かく制御できる。
* **デメリット**:
    * 高度なトラフィックルーティング機能（インテリジェントなロードバランサー）が必要。
    * エラー発生時の原因追跡が複雑になる。

| Pros | Cons |
| :--- | :--- |
| ✅ 複数バージョンを並行稼働可能 | ❌ 高度なロードバランサーが必要 |
| ✅ トラフィック分配を完全に制御 | ❌ エラー追跡が困難になる |

#### 6. シャドウ戦略 (Shadow)
本番トラフィックを新旧両方のバージョンに流しますが、**新バージョンからの応答はユーザーには返さず破棄**します。これにより、ユーザーに影響を与えることなく新バージョンの性能や安定性をテストできます。

* **流れ**:
    1.  稼働中のv1と並行して、新バージョンv2（シャドウ）をデプロイする。
    2.  本番トラフィックをv1とv2の両方に送る（フォークする）。
    3.  v1は通常通りユーザーに応答を返す。
    4.  v2もリクエストを処理するが、その応答はユーザーには返さず、システム内部でパフォーマンス等を監視・分析する。
* **メリット**:
    * **本番トラフィックを使って**、ユーザーに影響を与えずに性能テストができる。
    * ダウンタイムがない。
* **デメリット**:
    * **リソース（コスト）が2倍**かかる。
    * ユーザーが実際に操作するわけではないため、真のユーザーテストとは言えない。
    * 設定が複雑。

| Pros | Cons |
| :--- | :--- |
| ✅ 本番トラフィックで性能テスト可能 | ❌ **高コスト (リソースが2倍)** |
| ✅ ユーザーへの影響なし | ❌ 真のユーザーテストではない |
| ✅ ダウンタイムなし | ❌ 複雑なセットアップ |

---

### 戦略の比較まとめ

各戦略の特徴を一覧で比較します。

| 戦略 | ダウンタイムなし | 本番トラフィックでテスト | ユーザーのターゲティング | コスト | ロールバック時間 | ユーザーへの影響 | 設定の複雑さ |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| **リクリエイト** | ❌ | ❌ | ❌ | 低 | 遅 | 大 | 低 |
| **ローリング** | ✅ | ❌ | ❌ | 低 | 遅 | 小 | 中 |
| **ブルー/グリーン** | ✅ | ❌ | ❌ | 高 | 速 | 中 | 中 |
| **カナリー** | ✅ | ✅ | ❌ | 低 | 中 | 小 | 中 |
| **A/Bテスト** | ✅ | ✅ | ✅ | 低 | 中 | 小 | 高 |
| **シャドウ** | ✅ | ✅ | ❌ | 高 | 速 | 無 | 高 |

### 適切な戦略の選び方

* **リクリエイト**: 短いダウンタイムが許容される開発環境や重要度の低いアプリに。
* **ローリング**: ダウンタイムを避けたいが、シンプルにデプロイしたい場合に最適。
* **ブルー/グリーン**: ミッションクリティカルなアプリで、コストをかけてでも瞬時に安全な切り替えを行いたい場合に。
* **カナリー**: 新機能に不安があり、リスクを最小限に抑えながら市場の反応を見たい場合に。
* **A/Bテスト**: UIの変更など、複数案から最良のものをユーザーの反応を見て選びたい場合に。
* **シャドウ**: ユーザーに影響を与えずに、新バージョンの負荷耐性やバグを本番トラフィックでテストしたい場合に。

はい、承知いたしました。講義のトランスクリプトを基に、復習用の要点ノートをMarkdown形式で作成します。

-----

## Kubernetesにおけるローリングアップデート

このノートは、Kubernetesでアプリケーションを無停止で更新する**ローリングアップデート**の仕組み、事前準備、実行方法、そして問題発生時のロールバックについてまとめたものです。

### ローリングアップデートとは？

**ローリングアップデート**とは、アプリケーションのPod（コンテナの実行単位）を一度にすべて入れ替えるのではなく、**段階的に新しいバージョンのPodに入れ替えていく**更新方法です。これにより、ユーザーへのサービス提供を中断することなく（**ゼロダウンタイム**）、安全にアプリケーションを更新できます。

  - **目的**: サービスを停止させずにアプリケーションの変更を反映させる。
  - **特徴**:
      - Pod単位での自動化・制御された更新。
      - 更新に問題があれば、簡単な操作で元のバージョンに戻せる（**ロールバック**）。

### 事前準備：更新戦略の設定

ローリングアップデートを適切に行うには、事前の設定が重要です。

1.  **ヘルスチェックの設定**

      - **Liveness Probe**: Pod内のコンテナが正常に**動作しているか**をチェックします。異常があればコンテナは再起動されます。
      - **Readiness Probe**: Podが**リクエストを受け付け可能な状態か**をチェックします。準備ができていないPodにはトラフィックが送られません。

    > これらを設定することで、Kubernetesは安全に更新を進めるタイミングを判断できます。

2.  **更新戦略の定義 (YAMLファイル)**
    `Deployment`のマニフェストファイル（YAML）に、`strategy`フィールドを定義して更新方法を細かく制御します。

    ```yaml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: my-app-deployment
    spec:
      replicas: 10 # Podの総数を10に設定
      strategy:
        type: RollingUpdate # 更新戦略としてローリングアップデートを選択
        rollingUpdate:
          maxUnavailable: "50%" # 更新中、利用不可であってもよいPodの最大割合 (ここでは5Pod)
          maxSurge: 2         # 本来のPod数を超えて一時的に存在してよいPodの最大数 (ここでは最大12Podまで許容)
      # ... (以下、Podテンプレートなどの定義)
    ```

      - **`maxUnavailable`**: 更新中に利用できなくなるPodの最大数（または割合）。**ゼロダウンタイムを目指す場合は`0`に設定**します。
      - **`maxSurge`**: 更新中に一時的に作成を許可する、本来のPod数を超えるPodの最大数（または割合）。リソースに余裕があれば、これを増やすことで更新速度を上げられます。
      - **`minReadySeconds`** (オプション): 新しいPodがReady状態になってから、システムが安定するまで待機する秒数。この時間が経過してから次のPodの更新が始まります。

### アップデートの実行とロールバック

#### アップデートの実行手順

1.  **新しいDockerイメージの準備**
    アプリケーションの新しいバージョンをビルドし、Docker Hubなどのコンテナレジストリにプッシュします。
    ```bash
    # (例) Dockerfileからイメージをビルドし、タグを付けてプッシュする
    docker build -t your-username/hello-kubernetes:2.0 .
    docker push your-username/hello-kubernetes:2.0
    ```
2.  **Deploymentの更新**
    `kubectl set image`コマンドを使い、Deploymentが参照するコンテナイメージを新しいバージョンに更新します。
    ```bash
    # deployment <Deployment名> のコンテナ <コンテナ名> のイメージを更新
    kubectl set image deployment/hello-kubernetes hello-kubernetes=your-username/hello-kubernetes:2.0
    ```
3.  **更新状況の確認**
    `kubectl rollout status`コマンドで、ローリングアップデートの進捗を確認できます。
    ```bash
    kubectl rollout status deployment/hello-kubernetes
    # 出力例: deployment "hello-kubernetes" successfully rolled out
    ```

#### ロールバック（更新の取り消し）

更新後に問題が発覚した場合、`kubectl rollout undo`コマンドで簡単に一つ前のバージョンに戻すことができます。

```bash
# deployment "hello-kubernetes" を一つ前のリビジョンに戻す
kubectl rollout undo deployment/hello-kubernetes
```

実行後、`kubectl get pods`で確認すると、新しいバージョンのPodが終了し、古いバージョンのPodが再作成される様子がわかります。

### 更新戦略の比較

KubernetesのDeploymentには主に2つの更新戦略があります。

| 戦略名 | 更新方法 | ダウンタイム | リソース消費 | 用途 |
| :--- | :--- | :--- | :--- | :--- |
| **RollingUpdate (逐次更新)** | 古いPodを少しずつ停止させながら、新しいPodを起動する。 | **なし** | 一時的にPod数が増えるため、リソース消費は多め。 | **本番環境**など、サービスの無停止が求められる場合。（デフォルト） |
| **Recreate (一斉更新)** | 古いPodを**全て**停止してから、新しいPodを**全て**起動する。 | **あり** | Pod数が一時的に0になるため、リソース消費は少なめ。 | 開発環境や、ダウンタイムが許容される場合。 |

#### 更新プロセスの図解

**RollingUpdate (逐次更新) の流れ**
ユーザーアクセスは中断されません。

1.  v2のPod-A'が起動
2.  v1のPod-Aが停止
3.  v2のPod-B'が起動
4.  v1のPod-Bが停止
5.  ... (Pod数分繰り返す)

**Recreate (一斉更新) の流れ**
v1とv2が入れ替わる間、サービスが停止します。

1.  v1の全Pod (A, B, C) が停止
2.  (サービス停止期間)
3.  v2の全Pod (A', B', C') が起動

はい、承知いたしました。講義のトランスクリプトを基に、KubernetesのConfigMapとSecretに関する復習用の要点ノートをMarkdown形式で作成します。

-----

## KubernetesのConfigMapとSecret：設定情報の管理

アプリケーションのソースコード内に設定値（例: APIエンドポイント、機能フラグ）を直接書き込む（ハードコーディング）と、設定を変えるたびにコードの修正と再ビルドが必要になり非効率です。このノートでは、Kubernetesで**設定情報をコードから分離して管理する**ための2つの主要なオブジェクト、**ConfigMap**と**Secret**について解説します。

-----

### ConfigMap：機密ではない設定情報の管理 🔑

**ConfigMapとは？**
機密性の低い設定データを**キーと値のペア**で保存するためのAPIオブジェクトです。アプリケーションの設定をコンテナイメージから切り離す（デカップリングする）ことで、柔軟な環境設定が可能になります。

  * **特徴**:
      * 平文で保存され、暗号化は提供されないため、**パスワードなどの機密情報には使用しない**。
      * 保存できるデータサイズの上限は**1MB**。
      * 複数のPodやDeploymentで同じConfigMapを再利用できる。

#### ConfigMapの作成方法

主に3つの方法があります。

1.  **コマンドラインで直接値を指定 (`--from-literal`)**
    キーと値を直接コマンドで指定して作成する最も簡単な方法です。

    ```bash
    # 'myconfig'という名前のConfigMapに、キー'message'、値'Hello from command line'を設定
    kubectl create configmap myconfig --from-literal=message="Hello from command line"
    ```

2.  **ファイルから作成 (`--from-file`)**
    `key=value`形式で記述されたプロパティファイルや、ディレクトリ全体を読み込んで作成します。複数の設定値をまとめて管理するのに便利です。

    ```bash
    # my.propertiesファイルを作成
    echo "message=Hello from the my.properties file" > my.properties

    # ファイルからConfigMapを作成
    kubectl create configmap myconfig-from-file --from-file=my.properties
    ```

3.  **YAMLマニフェストファイルから作成**
    設定内容をYAMLファイルとして定義し、`kubectl apply`で適用します。Gitなどでバージョン管理がしやすく、再利用性に優れています。

    ```yaml
    # my-config.yaml
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: my-yaml-config
    data:
      message: "Hello from the YAML file"
      another.key: "some other value"
    ```

    ```bash
    # YAMLファイルを適用してConfigMapを作成
    kubectl apply -f my-config.yaml
    ```

#### ConfigMapの利用方法

作成したConfigMapは、主に2つの方法でPod内のアプリケーションから利用します。

1.  **環境変数として読み込む**
    DeploymentのYAMLファイルで、ConfigMapの値をコンテナの環境変数としてマッピングします。

    ```yaml
    # deployment.yaml の一部
    spec:
      containers:
      - name: my-app-container
        image: my-app
        env:
          - name: MESSAGE_FROM_CONFIG # コンテナ内で使われる環境変数名
            valueFrom:
              configMapKeyRef:
                name: myconfig       # 利用するConfigMapの名前
                key: message        # 利用するデータのキー
    ```

2.  **ファイルとしてボリュームにマウントする**
    ConfigMapのデータをファイルとしてコンテナ内の特定のパスに配置します。設定ファイル自体をコンテナに渡したい場合に有効です。

-----

### Secret：機密情報（パスワード等）の管理 🔒

**Secretとは？**
パスワード、APIキー、TLS証明書など、**機密性の高い情報**を保存するためのオブジェクトです。基本的な使い方はConfigMapと似ていますが、値が自動的に**Base64でエンコード**されて保存される点が大きな違いです。

  * **注意点**: Base64は暗号化ではなく、単なるエンコーディングです。誰でも簡単にデコード（復号）できます。そのため、Secretは機密情報を平文で扱うより安全ですが、RBACによるアクセス制御や、より強固な暗号化を提供する外部ツール（例: HashiCorp Vault）との連携を検討することが推奨されます。

#### Secretの作成方法

ConfigMapと同様に、コマンドラインやYAMLファイルから作成できます。

```bash
# 'mysecret'という名前のSecretに、キー'api-creds'、値'supersecret123'を設定
kubectl create secret generic mysecret --from-literal=api-creds='supersecret123'
```

`kubectl get secret mysecret -o yaml`で中身を確認すると、値がエンコードされていることがわかります。

#### Secretの利用方法

1.  **環境変数として読み込む**
    ConfigMapと同様に、Secretの値を環境変数としてコンテナに渡します。

    ```yaml
    # deployment.yaml の一部
    spec:
      containers:
      - name: my-app-container
        image: my-app
        env:
          - name: API_CREDS # コンテナ内で使われる環境変数名
            valueFrom:
              secretKeyRef:
                name: mysecret # 利用するSecretの名前
                key: api-creds  # 利用するデータのキー
    ```

2.  **ファイルとしてボリュームにマウントする**
    機密情報をファイルとしてコンテナ内にマウントします。環境変数よりも安全な方法とされています。

    ```yaml
    # deployment.yaml の一部
    spec:
      containers:
      - name: my-app-container
        image: my-app
        volumeMounts:
        - name: secret-volume
          mountPath: "/etc/api" # コンテナ内のマウント先パス
          readOnly: true
      volumes:
      - name: secret-volume
        secret:
          secretName: mysecret # 利用するSecretの名前
    ```

## Service Binding (サービスバインディング)

Service Bindingは、アプリケーションが外部サービス（データベース、REST APIなど）を利用するために必要な設定や認証情報を扱うプロセスです。これにより、機密データを保護しつつ、サービス認証情報を自動的に提供することができます。

### Service Bindingの役割と目的

  * **外部サービスとの連携**: アプリケーションから外部サービスを安全に利用するための仕組みを提供します。
  * **認証情報の自動管理**: サービスに接続するための認証情報（資格情報）を自動的に管理し、提供します。
  * **機密データの保護**: 認証情報をKubernetesの**Secret**として扱い、機密データを保護します。

-----

### Service Bindingのステップ（IBM Cloudを例に）

外部サービスをKubernetesクラスターにバインドする手順は、以下の通りです。

1.  **サービスインスタンスのプロビジョニング**:

      * 利用したい外部サービス（例：IBM Cloud Tone Analyzer）のインスタンスを作成します。
      * CLI（コマンドラインインターフェース）またはWeb上のカタログから実行可能です。

2.  **サービスのバインドとSecretの作成**:

      * 作成したサービスインスタンスをKubernetesクラスターに**バインド**します。
      * この操作により、サービス認証情報が自動的に生成され、**Kubernetes Secret**として保存されます。
      * 認証情報はJSON形式で、Base64エンコードされてSecretに格納されます。

3.  **Secretの確認**:

      * `Get Secrets`コマンドやKubernetesダッシュボードで、作成されたSecretオブジェクトを確認します。

-----

### アプリケーションでのSecretの利用方法

アプリケーションコードでSecretに保存された認証情報を利用する方法は、主に以下の2つです。

1.  **ボリュームとしてマウント**:

      * SecretをPodにボリュームとしてマウントします。
      * これにより、`binding`という名前のJSONファイルがPod内の指定されたディレクトリに作成され、ファイルから認証情報を読み込めます。

2.  **環境変数として参照**:

      * Secretのキーと値を環境変数にマッピングします。
      * アプリケーションコードでは、`binding.APIKey`、`binding.username`、`binding.password`などの環境変数として認証情報にアクセスできます。

#### Node.jsでの環境変数利用例

```javascript
const express = require('express');
const ToneAnalyzerV3 = require('watson-developer-cloud/tone-analyzer/v3');

const app = express();

// 環境変数から認証情報を取得
const username = process.env.BINDING_USERNAME;
const password = process.env.BINDING_PASSWORD;
const apiKey = process.env.BINDING_APIKEY;

const toneAnalyzer = new ToneAnalyzerV3({
  username: username,
  password: password,
  version: '2017-09-21',
  iam_apikey: apiKey
});

// 以降、toneAnalyzerオブジェクトを使用してサービスを呼び出す
```

## Kubernetesとコンテナ化が小売業にもたらす変革

### 講義のテーマ
小売業におけるITインフラの課題と、それらを解決するための**Kubernetes**と**コンテナ化**の活用

### 小売業が直面するIT課題
小売業は、オンラインと実店舗の両方でシームレスな顧客体験を提供し、ピーク時のトラフィック急増に対応する必要があるため、以下のIT課題に直面しています。

* **スケーラビリティの問題**: セールやホリデーシーズン中のトラフィック急増にシステムが耐えられず、パフォーマンス低下やダウンタイムが発生する。
* **デプロイメントの遅延**: 新機能やアップデートの導入に時間がかかり、頻繁な変更が困難。
* **リソース利用の非効率**: 過剰なリソース確保（オーバープロビジョニング）によるコスト増と、リソース不足によるパフォーマンス低下の両方が課題。
* **不十分な災害復旧**: システム障害発生時の復旧戦略が脆弱で、大きな損失につながる可能性がある。

### 課題解決のための戦略的アプローチ
これらの課題を克服するため、以下の目標が立てられます。

1.  **スケーラビリティの強化**: 負荷変動に動的に対応できる柔軟なインフラの構築。
2.  **デプロイメントサイクルの加速**: ダウンタイムを最小限に抑え、新機能を迅速に導入できる効率的なデプロイプロセス。
3.  **リソース利用の最適化**: 運用コスト削減と効率化のためのリソース管理の改善。
4.  **災害復旧体制の強化**: ダウンタイムを短縮し、業務を継続するための信頼性の高い計画。

### 変革をもたらすソリューション：Kubernetesとコンテナ化
小売業の課題を解決する鍵となるのが、**マイクロサービスアーキテクチャ**、**Dockerによるコンテナ化**、そして**Kubernetesによるオーケストレーション**です。

#### 1. マイクロサービスとコンテナ化
* **マイクロサービスアーキテクチャ**: 大規模なアプリケーションを独立した小さなサービス（マイクロサービス）に分割することで、個別に開発、デプロイ、スケーリングが可能になります。
* **コンテナ化（Docker）**: これらのマイクロサービスをコンテナ化することで、開発・テスト・本番環境での一貫性が確保されます。

#### 2. Kubernetesの活用
Kubernetesはコンテナ化されたアプリケーションのデプロイ、スケーリング、管理を自動化する**オーケストレーション**ツールです。

* **負荷分散とオートスケーリング**: ピーク時には自動的にスケールアップし、オフピーク時にはスケールダウンすることで、常に最適なパフォーマンスとコスト効率を維持します。
* **CI/CDパイプラインの導入**: Jenkins, GitLab CI/CDなどのツールと組み合わせることで、アプリケーションのビルド、テスト、デプロイプロセスを自動化し、開発サイクルを加速します。
    * **ブルー/グリーンデプロイメント**: 新バージョンを「グリーン」、旧バージョンを「ブルー」として並行稼働させ、切り替えることでダウンタイムなしのアップデートを実現します。
* **リソース管理とコスト最適化**: リアルタイムの需要に基づいてリソースを動的に割り当てることで、利用率を向上させ、無駄を削減します。
* **災害復旧と高可用性の強化**: 複数のリージョンにKubernetesクラスターをデプロイし、自動バックアップツール（Veleroなど）を使用することで、高い可用性と迅速な災害復旧を可能にします。

### Kubernetesとコンテナ化がもたらす小売業への影響
* **スケーラビリティとパフォーマンスの向上**: セール時のトラフィック急増にもダウンタイムなく対応でき、安定した顧客体験を提供します。
* **デプロイメントサイクルの加速**: 新機能のデプロイ時間が数週間から数分に短縮され、市場投入までの時間を大幅に短縮します。
* **リソース利用の最適化**: 動的なリソース管理により、運用コストを大幅に削減します。
* **災害復旧体制の強化**: データセンターの障害時でも、サービスの中断を最小限に抑え、収益損失を防ぎます。

## Kubernetes `kubectl` チートシート

| コマンド | 説明 | 具体的な使い方・例 |
| :--- | :--- | :--- |
| **`kubectl get`** | リソース（Pod、Deploymentなど）の情報を取得します。 | `kubectl get deployments` |
| **`kubectl autoscale`** | **Horizontal Pod Autoscaler (HPA)**を作成し、Podのレプリカ数を自動的に増減させます。 | `kubectl autoscale deployment my-app --min=2 --max=10 --cpu-percent=80` |
| **`kubectl create`** | リソース（ConfigMap、Deploymentなど）を作成します。 | `kubectl create configmap my-config --from-file=./my-config.yaml` |
| **`kubectl scale`** | Deploymentなどのレプリカ数を手動で変更します。 | `kubectl scale deployment my-app --replicas=5` |
| **`kubectl set image`** | Deploymentのコンテナイメージを更新します。 | `kubectl set image deployment my-app my-container=my-new-image:v2` |
| **`kubectl rollout`** | Deploymentのロールアウト（更新の進行状況）を管理します。 | `kubectl rollout status deployment/my-app` |
| **`kubectl rollout restart`** | Deploymentを再起動します。 | `kubectl rollout restart deployment/my-app` |
| **`kubectl rollout undo`** | ロールアウトを前のバージョンに戻します（ロールバック）。 | `kubectl rollout undo deployment/my-app` |